{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiation √† la üîé reconnaissance d'entit√©s nomm√©es üîç avec [spaCy](https://spacy.io/)\n",
    "\n",
    "<p style=\"font-size:small;font-style:italic\">filename: \"intro-ner-spacy-student.ipynb\" ‚Äî generation_timestamp: 2024-03-06_083613 ‚Äî source_commit: fee50bd7343b4e4611ccd3af1e3e3e0142a8a144</p>\n",
    "\n",
    "[![](https://img.shields.io/badge/Google_%20_Colab-Cliquez_ici_pour_√©diter_ce_notebook-blue?logo=googlecolab)](https://colab.research.google.com/github/HueyNemud/tnah_atelierpython/blob/main/session_3/sequence_1_2/intro-ner-spacy-student.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**üëã Bonjour !**\n",
    "\n",
    "Cette activit√© a pour objectif de vous apprendre √† utiliser la biblioth√®que [spaCy](https://spacy.io/) et de mettre en place un projet de reconnaissance d'entit√©s nomm√©es (*[Named entities recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)*, ou *NER* en anglais).\n",
    "\n",
    "Au travers d'exercices et d'observations simples qui vous permettront d'envisager la cha√Æne de traitement de donn√©es dans son ensemble, vous allez prendre en main quelques d'outils essentiels.\n",
    "Ainsi, vous devriez pouvoir r√©appliquer cette approche sur des donn√©es de votre choix, apr√®s cet atelier, en toute autonomie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Contenu de cette activit√©"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. Installation et g√©n√©ralit√©s √† propos de spaCy\n",
    "3. Reconna√Ætre des entit√©s nomm√©es avec un mod√®le existant et visualiser les r√©sultats\n",
    "4. Traiter les donn√©es de notre corpus d'exemple\n",
    "5. √âvaluer objectivement la performance d'un mod√®le de langage\n",
    "6. Annoter un jeu de donn√©es complet : aper√ßu du probl√®me\n",
    "7. Entra√Æner un mod√®le sp√©cialis√© et comparer sa performance\n",
    "8. Export des donn√©es pour une utilisation ult√©rieure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üó∫Ô∏è Symboles utilis√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Au cours de cette activit√©, vous aurez des actions √† r√©aliser.\n",
    "  Celles-ci sont indiqu√©es par les symboles üöß, üèóÔ∏è, üõ†Ô∏è, üë∑.\n",
    "- Certains √©l√©ments n√©cessitant votre attention sont indiqu√©s par des symboles comme üö®, ‚ö†Ô∏è, üëâ.\n",
    "- Des √©l√©ments d'information suppl√©mentaires sont indiqu√©s par le symbole ‚ÑπÔ∏è.\n",
    "- Et finalement, certains √©l√©ments sont indiqu√©s pour vous permettre de prolonger cette activit√© en dehors du cr√©neau r√©serv√© et sont indiqu√©s par le symbole ü§ì.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources et licence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce cours a √©t√© cr√©√© par <a rel=\"cc:attributionURL dct:creator\" property=\"cc:attributionName\" href=\"https://jchazalon.github.io\">Joseph Chazalon</a> : \n",
    "\n",
    "> Consortium HumaNum Ariane, Joseph Chazalon, Atelier d'initiation √† la reconnaissance d'entit√©s nomm√©es avec spaCy, en ligne : <https://github.com/jchazalon/hn-ariane-ner-tuto-2023>, 9 novembre 2023, Lyon.\n",
    "\n",
    "Les donn√©es de cet atelier sont adapt√©es du ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù par Carmen Brando, Francesca Frontini, et Ioana Galleron sous licence [Creative Commons - Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/). \n",
    "\n",
    "> Brando, Carmen; Frontini, Francesca and Galleron, Ioana, 2022, French ELTEC NER Open Dataset, ILC-CNR for CLARIN-IT repository hosted at Institute for Computational Linguistics \"A. Zampolli\", National Research Council, in Pisa, [http://hdl.handle.net/20.500.11752/OPEN-986](http://hdl.handle.net/20.500.11752/OPEN-986).\n",
    "\n",
    "\n",
    "Les documents et donn√©es sont sous licence [Creative Commons - Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ C'est parti !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le lien vers la pr√©sentation : <https://docs.google.com/presentation/d/1_RycfOOeQo8XZNojsx7SzaSDyhepj-8n8w7xMpf9UGI/edit>\n",
    "\n",
    "Vous pouvez aussi acc√©der √† tous les fichiers de cette activit√© (pour les t√©l√©charger par exemple) sur GitHub : <https://github.com/jchazalon/hn-ariane-ner-tuto-2023>\n",
    "\n",
    "Parcourez ce *notebook* dans l'ordre, et n'h√©sitez pas √† solliciter les formateurs d√®s que vous avez une question.\n",
    "Aux √©tapes cl√©s de l'atelier, ces derniers utiliseront les supports de cours pour introduire certaines notions collectivement.\n",
    "Vous pouvez cependant avancer √† votre rythme en toute autonomie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation et g√©n√©ralit√©s √† propos de spaCy\n",
    "Dans cette section, nous allons installer *spaCy* et comprendre quelques principes de base essentiels.\n",
    "\n",
    "En particulier, nous allons nous int√©resser aux objets repr√©sentant un mod√®le de langage et un ¬´¬†document¬†¬ª en cours d'analyse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Installation de spaCy\n",
    "Avant toute autre chose, nous devons installer *spaCy* !\n",
    "\n",
    "Nous avons pr√©par√© un fichier d√©crivant les paquets Python n√©cessaires √† la r√©alisation de cette activit√©.\n",
    "Si vous n'avez pas d√©j√† install√© et configur√© un environnement de travail, vous pouvez ex√©cuter la cellule suivante pour le faire.\n",
    "\n",
    "üëâ Notez le `!` qui pr√©c√®de l'instruction : il signifie que la ligne n'est pas une instruction Python, mais une instruction shell ex√©cut√©e sur la machine qui ex√©cute ce *notebook*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour installer spaCy et les autres outils n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/jchazalon/hn-ariane-ner-tuto-2023/main/requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Import de la biblioth√®que\n",
    "Pour rendre disponible les objets, fonctions et autres √©l√©ments propos√©s par la biblioth√®que, nous avons besoin de la charger et de d√©finir un nom qui permet d'y faire r√©f√©rence.\n",
    "\n",
    "C'est le r√¥le de l'instruction `import`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour importer *spaCy* dans votre environnement d'ex√©cution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 L'objet [`Language`](https://spacy.io/api/language)\n",
    "L'objet [`Language`](https://spacy.io/api/language) sert √† repr√©senter une cha√Æne de traitements qui \n",
    "- poss√®de une repr√©sentation interne d'un langage \n",
    "- et permet de calculer un certain nombre d'√©l√©ments √† partir d'un texte ou d'autres √©l√©ments d√©j√† calcul√©s.\n",
    "\n",
    "On peut construire une nouvelle cha√Æne de traitements de plusieurs fa√ßons.\n",
    "La mani√®re la plus simple est de construire une cha√Æne de traitement **vide** (ou presque) pour le fran√ßais √† l'aide de la \"fabrique\" √† cha√Ænes de traitement [`spacy.blank(LANGAGE)`](https://spacy.io/api/top-level/#spacy.blank)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©tez et ex√©cutez la cellule suivante pour cr√©er un mod√®le de langue vide pour le fran√ßais üá´üá∑\n",
    "<details>\n",
    "<summary>Cliquez ici pour voir un indice</summary>\n",
    "\n",
    "N'h√©sitez pas √† consulter l'aide officielle de la fonction [`spacy.blank(LANGAGE)`](https://spacy.io/api/top-level/#spacy.blank) pour savoir comment l'utiliser !\n",
    "\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Cliquez ici pour voir la solution</summary>\n",
    "\n",
    "```python\n",
    "nlp = spacy.blank(\"fr\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy._____(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La cha√Æne de traitements contient diff√©rents traitements appliqu√©s les uns apr√®s les autres.\n",
    "On peut afficher cette liste de traitements √† l'aide de l'attribut `pipe_names` de l'objet `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, une cha√Æne de traitement ne contient rien‚Ä¶ Sauf un *tokenizer*, d'o√π l'importance de pr√©ciser la langue !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 L'objet [`Doc`](https://spacy.io/api/doc)\n",
    "On obtient un objet [`Doc`](https://spacy.io/api/doc) en appliquant la cha√Æne de traitement [`Language`](https://spacy.io/api/language) √† une cha√Æne de texte.\n",
    "\n",
    "Cet objet [`Doc`](https://spacy.io/api/doc) est central pour spaCy car il va √™tre progressivement enrichi par chacun de traitements qui va venir y piocher les informations dont il a besoin en entr√©e, et y ajouter les informations qu'il a calcul√©es.\n",
    "\n",
    "Ce principe est r√©sum√© dans la figure suivante, extraire de la documentation officielle de spaCy :  \n",
    "![](https://spacy.io/images/pipeline.svg)\n",
    "\n",
    "Par exemple, le composant \"ner\" (que nous utiliserons plus tard) va venir affecter une √©tiquette (*\"label\"*) √† chacun des *tokens* du document. Il va stocker cette information dans un nouvel attribut `doc.ents` du document.\n",
    "\n",
    "L'attribut `doc.text` contient quant √† lui la liste des *tokens* extraits.\n",
    "\n",
    "<!-- More complex architecture diagram ![](https://spacy.io/images/architecture.svg) -->\n",
    "\n",
    "Pour appliquer un mod√®le de langue √† une cha√Æne de texte, il suffit d'utiliser la variable `nlp` cr√©√© comme une fonction !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©√© en traitant une chaine de caract√®res avec l'objet nlp\n",
    "doc = nlp(\"Bonjour tout le monde !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut parcourir les *tokens* extraits d'un [`Doc`](https://spacy.io/api/doc) √† l'aide d'une boucle classique en Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 L'objet [`Token`](https://spacy.io/api/token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©tez et ex√©cutez la cellule suivante pour afficher le contenu de chaque token du document\n",
    "Un objet [`Token`](https://spacy.io/api/token) contient un certain nombre d'[attributs](https://spacy.io/api/token#attributes) int√©ressants.\n",
    "\n",
    "Tous ces attributs ne sont pas n√©cessairement calcul√©s avec un mod√®le de langue vide, mais il est d√©j√† possible d'en observer un certain nombre.\n",
    "En particulier, vous devez utiliser l'attribut `Token.text` pour acc√©der √† sa repr√©sentation textuelle.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It√®re sur les tokens dans un Doc\n",
    "for ____ in ____:\n",
    "    print(____.____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'obtenir des informations utiles √† propos des *tokens* de notre document sans m√™me avoir besoin d'utiliser un mod√®le de langue complexe.\n",
    "\n",
    "Voici un exemple que vous pouvez observer, qui tire profit des [attributs](https://spacy.io/api/token#attributes) `Token.i` (qui indique l'identifiant du *token* au sein du document parent), `Token.is_alpha`, `Token.is_punct` et `Token.like_num`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autres attributs des tokens et des spans\n",
    "doc2 = nlp(\"Cela co√ªte 5 ‚Ç¨.\")\n",
    "\n",
    "print(\"Index :   \", [token.i for token in doc2])\n",
    "print(\"Text :    \", [token.text for token in doc2])\n",
    "\n",
    "print(\"is_alpha :\", [token.is_alpha for token in doc2])\n",
    "print(\"is_punct :\", [token.is_punct for token in doc2])\n",
    "print(\"like_num :\", [token.like_num for token in doc2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible d'acc√©der √† un token particulier, gr√¢ce √† son indice dans le document."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour afficher le premier token du document\n",
    "N'h√©sitez pas √† en afficher d'autres pour observer ce comportement.\n",
    "\n",
    "‚ÑπÔ∏è Notez qu'il n'est pas toujours n√©cessaire d'appeler `print()` avec Jupyter : la valeur de retour de la derni√®re instruction sera affich√©e, au format texte par d√©faut ou au format HTML si une repr√©sentation plus riche est disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut s√©lectionner un token particulier, gr√¢ce √† son indice dans le document\n",
    "token = doc[0]\n",
    "token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 L'objet [Span](https://spacy.io/api/span)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet [Span](https://spacy.io/api/span) est un autre objet utile √† conna√Ætre, qui repr√©sente une s√©quence de *tokens* contigu√´ au sein d'un document."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß <b>Essayez √† pr√©sent de s√©lectionner et afficher les <i>tokens</i> \"tout le monde\".</b>\n",
    "\n",
    "<details>\n",
    "<summary>Indices</summary>\n",
    "\n",
    "Vous pouvez utiliser les *ranges* pour s√©lectionner plusieurs √©l√©ments d'un it√©rable. Voici un exemple de la syntaxe √† utiliser :\n",
    "```python\n",
    "ma_liste = [0, 1, 2, 3]\n",
    "print(ma_liste[1:3])\n",
    "# Affiche : [1, 2]\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On applique cette syntaxe pour s√©lectionner les tokens du rang 1 (2e token, inclus) au rang 4 (non inclus) :\n",
    "\n",
    "```python\n",
    "span = doc[1:4]\n",
    "span\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut √©galement utiliser les \"ranges\" Python pour s√©lectionner plusieurs tokens\n",
    "span = doc[____]\n",
    "span"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä l'instar des objets Token, ils poss√®dent √©galement des [attributs](https://spacy.io/api/span#attributes) int√©ressants, comme `Span.text` qui permet d'en obtenir une repr√©sentation textuelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut √©galement acc√©der aux attributs d'un span\n",
    "span.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Reconna√Ætre des entit√©s nomm√©es avec un mod√®le existant et visualiser les r√©sultats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons √† pr√©sent utiliser un mod√®le existant mis √† disposition par les cr√©ateurs de spaCy pour comprendre le fonctionnement d'un mod√®le de langue int√©grant un composant de reconnaissance d'entit√©s nomm√©es.\n",
    "\n",
    "Pour cela, nous allons commencer par utiliser une cha√Æne de traitement entra√Æn√©e pour le fran√ßais."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Choix, installation et chargement du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Cherchez [dans la documentation](https://spacy.io/models/fr) un mod√®le adapt√© pour d√©marrer\n",
    "Trouvez le nom du **plus petit mod√®le contenant un composant NER** qui nous permettra de faire des premi√®res exp√©riences rapides.\n",
    "\n",
    "La taille du mod√®le est indiqu√©e dans le champ *\"Size\"*.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "On trouve 4 mod√®les :\n",
    "1. `fr_core_news_sm` : un petit mod√®le adapt√© pour nos premi√®res exp√©riences, contenant tous les composants n√©cessaires üëà *utilisez celui-ci pour mettre au point votre approche !*\n",
    "2. `fr_core_news_md` : un mod√®le de taille moyenne, contenant √©galement tous les composants de base, adapt√© √† des cas simples pour lesquels l'efficacit√© prime\n",
    "3. `fr_core_news_lg` : un mod√®le large, adapt√© au travail sur CPU, contenant tous les composants de base et offrant de bonnes performances.\n",
    "4. `fr_dep_news_trf` : un nouveau mod√®le qui devrait offrir les meilleures performances, mais ne disposant pas de composant NER pr√©-entra√Æn√© et pour lequel il faut pr√©f√©rer une ex√©cution sur GPU.\n",
    "</details>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez √† pr√©sent la commande suivante pour t√©l√©charger les fichiers du mod√®le\n",
    "Indiquez le nom du mod√®le que vous avez s√©lectionn√©.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy download fr_core_news_sm\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download __________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons √† pr√©sent charger ce nouveau mod√®le √† l'aide de la commande [`spacy.load(NOM_DU_MOD√àLE)`](https://spacy.io/api/top-level#spacy.load)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez la cellule suivante pour charger le mod√®le que vous venez de t√©l√©charger.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "````\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Ex√©cutez √† pr√©sent la cellule suivante pour v√©rifier que nous disposons bien de nouveau composants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Premiers pas avec un mod√®le sur √©tag√®re üì¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons √† pr√©sent utiliser notre mod√®le pour extraire des informations plus int√©ressantes d'un texte, comme de l'[√©tiquetage morpho-syntaxique](https://fr.wikipedia.org/wiki/%C3%89tiquetage_morpho-syntaxique), aussi appel√© √©tiquetage grammatical, ou *POS tagging* (*part-of-speech tagging*) en anglais, pour jouer un peu avant de nous recentrer sur la reconnaissance d'entit√©s nomm√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging example\n",
    "doc = nlp(\"La journ√©e de formation √† Lyon se d√©roule bien.\")\n",
    "print(f\"{'Token':>10s}\", f\"{'POS':>6s}\", f\"{'Synt. dep. rel.':>18s}\", f\"{'Synt. parent':>15s}\")\n",
    "print(\"-\"*50)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:>10s}\", f\"{token.pos_:>6s}\", f\"{token.dep_:>18s}\", f\"{token.head.text:>15s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Pourquoi certains [attributs des tokens](https://spacy.io/api/token#attributes) terminent-ils par un `_` ?  \n",
    "C'est parce que la valeur de base (sans le `_`) est un identifiant (un nombre entier) qui pointe vers une case d'un grand dictionnaire d'√©l√©ments connus. C'est une fa√ßon efficace, mais peu lisible, de stocker l'information. D'o√π la variante lisible !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est √©galement possible de demander √† spaCy des explications sur un terme utilis√© √† l'aide de la fonction `spacy.explain()`.\n",
    "\n",
    "Vous pouvez modifier la cellule ci-dessous pour obtenir plus d'information sur un terme si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"advmod\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Reconnaissance d'entit√©s nomm√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une nouvelle phrase qui contient deux entit√©s classiques : une **personne** (√† laquelle correspondra l'√©tiquette `PER`) et un **lieu** (qui sera rep√©r√© par l'√©tiquette `LOC`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Analysons-la avec notre nouveau mod√®le !\n",
    "Ex√©cutez la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Joseph est venu en train √† Lyon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien qu'on puisse lire la valeur de l'attribut `ent_type_` de chaque objet [`Token`](https://spacy.io/api/token#attributes), il est souvent plus pratique de ne lister que les entit√©s nomm√©es d√©tect√©es dans un document. De plus, certaines entit√©s peuvent contenir plusieurs *tokens*, ce qui rend leur extraction manuelle plus d√©licate !\n",
    "\n",
    "Heureusement, l'objet [`Doc`](https://spacy.io/api/doc) dispose d'une propri√©t√© [`Doc.ents`](https://spacy.io/api/doc#ents) qui renvoie une liste d'objets [`Span`](https://spacy.io/api/span) qui repr√©sentent les positions des entit√©s et les √©tiquettes (*labels*) qui leur sont associ√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Compl√©tez le code de la cellule ci-dessous pour afficher le texte et le *label* de chaque entit√©\n",
    "- Utilisez les attributs `start`, `end` de chaque `Span` pour s√©lectionner le fragment de document couvert √† l'aide d'un *range* Python\n",
    "- Utiliser leur attribut `label_` pour afficher le type d'entit√© d√©tect√© sous forme textuelle\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "for ent in doc.ents:\n",
    "    print(doc[ent.start:ent.end], ent.label_)\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.____:\n",
    "    print(doc[____:____], ____)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualisation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy dispose d'un moteur de visualisation tr√®s pratique, qui produit de tr√®s jolis r√©sultats.\n",
    "\n",
    "Il est utilisable via le module [`displacy`](https://spacy.io/universe/project/displacy) qui permet de visualiser les informations extraites d'un document, en particulier les [entit√©s nomm√©es](https://spacy.io/usage/visualizers#ent).\n",
    "\n",
    "Encore mieux, il peut √™tre [utilis√© dans un notebook](https://spacy.io/usage/visualizers#jupyter) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Vous pouvez m√™me modifier le style d'affichage en indiquant `\"dep\"` pour afficher le graphe de d√©pendances syntaxiques de notre document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "treacher"
    ]
   },
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traiter les donn√©es de notre corpus d'exemple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons √† pr√©sent utiliser notre mod√®le pour traiter les donn√©es de notre corpus et r√©aliser une premi√®re analyse qualitative superficielle des r√©sultats produits.\n",
    "\n",
    "Pour vous illustrer la proc√©dure √† suivre avec vos propres donn√©es, nous allons vous montrer comment acc√©der √† une collection de fichiers texte :\n",
    "1. si vous utilisez **Google Colab**, en utilisant le contenu d'un de vos dossiers Google Drive,\n",
    "2. si vous utilisez **votre propre machine**, en indiquant simplement le chemin vers lequel les fichiers sont stock√©s.\n",
    "\n",
    "Ces deux cas sont assez semblables, la seule diff√©rence est qu'avec Google Colab, vous utiliser une machine virtuelle distance, et que vous ne pouvez contr√¥ler cette derni√®re que par l'interm√©diaire de l'interface de Colab (un notebook am√©lior√©)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è R√©cup√©rer des fichiers int√©ressants sur votre machine\n",
    "Vous allez t√©l√©charger le jeu de donn√©es original ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù par Carmen Brando, Francesca Frontini, et Ioana Galleron.\n",
    "\n",
    "[![üì¶ Cliquez ici pour t√©l√©charger le jeu de donn√©es](https://img.shields.io/badge/%F0%9F%93%A6-Cliquez_ici_pour_t%C3%A9l%C3%A9charger_le_jeu_de_donn%C3%A9es-blue)](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/bitstream/handle/20.500.11752/OPEN-986/French_ELTEC_NER_Open_Dataset.zip) et enregistrez-le dans votre dossier de travail."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Utiliser Drive pour envoyer des fichiers sur Colab\n",
    "**Si vous ex√©cutez votre *notebook* sur votre propre machine, vous pouvez passer cette partie.**\n",
    "\n",
    "√Ä pr√©sent, copiez le fichier Zip t√©l√©charg√© dans un dossier de votre choix (par exemple \"Formation Ariane\") de votre Drive.\n",
    "\n",
    "Nous sommes maintenant pr√™ts √† \"monter\" votre Drive sur la machine virtuelle que vous utilisez sur Google Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©tez et ex√©cutez la cellule ci-dessous et autorisez Colab √† acc√©der √† votre Drive\n",
    "Une fois cette op√©ration r√©alis√©e, votre machine virtuelle Google Colab pourra acc√©der au fichier que vous venez de d√©poser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "\n",
    "# COMPL√âTEZ CETTE LIGNE AVEC LE NOM DU DOSSIER DANS LEQUEL VOUS AVEZ D√âPOS√â VOTRE FICHIER\n",
    "# > just access \"/gdrive/My Drive/...\"\n",
    "FOLDER_NAME = \"TNAH_Atelier_Python\"  # üëàüëàüëà\n",
    "\n",
    "# Si vous avez chang√© le nom du fichier, vous pouvez l'indiquer ici\n",
    "ZIP_FILENAME = \"French_ELTEC_NER_Open_Dataset.zip\"\n",
    "\n",
    "# On v√©rifie qu'on arrive bien √† acc√©der au fichier\n",
    "import os.path\n",
    "dataset_zip_path = f\"/gdrive/My Drive/{FOLDER_NAME}/{ZIP_FILENAME}\"\n",
    "if os.path.exists(dataset_zip_path):\n",
    "    print(\"Fichier bien trouv√© !\")\n",
    "else:\n",
    "    err_msg = f\"Erreur, le fichier n'a pas √©t√© trouv√© au chemin '{dataset_zip_path}'.\"\n",
    "    print(err_msg)\n",
    "    raise ValueError(err_msg)\n",
    "dataset_destination_dir = \"./dataset/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è Si vous travaillez sur votre machine personnelle, d√©-commentez, modifiez et ex√©cutez la cellule suivante\n",
    "Ceci nous servira √† indiquer :\n",
    "1. o√π est rang√© le fichier ZIP contenant le jeu de donn√©es\n",
    "2. o√π il faudra d√©compresser les fichiers qu'il contient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_zip_path = \"/home/jchazalo/Downloads/French_ELTEC_NER_Open_Dataset.zip\"\n",
    "# dataset_destination_dir = \"/home/jchazalo/tmp/datasets\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 D√©compresser les fichiers\n",
    "Afin de faciliter l'acc√®s aux diff√©rents fichiers, nous allons √† pr√©sent d√©compresser les fichiers du jeu de donn√©es.\n",
    "\n",
    "Nous allons utiliser les 100 fichiers texte extraits de romans du 19e si√®cle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Ex√©cutez la cellule suivante et v√©rifiez qu'aucune erreur n'est rencontr√©e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence par v√©rifier qu'on trouve bien le fichier et que son contenu n'a pas √©t√© alt√©r√©\n",
    "!echo \"7dc395be9d84ac481ff6cf0a726862b66967898986f387dd5659d554394101d6  {dataset_zip_path}\" | sha256sum -c -\n",
    "# On v√©rifie que le r√©pertoire de destination existe et on le cr√©e sinon\n",
    "!mkdir -p \"{dataset_destination_dir}\"\n",
    "# On d√©compresse le fichier dans le r√©pertoire de destination\n",
    "!unzip \"{dataset_zip_path}\" -d \"{dataset_destination_dir}\"\n",
    "# On liste le contenu du r√©pertoire de destination : on s'attend √† trouver le r√©pertoire \"French_ELTEC_NER_Open_Dataset/texts\" et √† ce qu'il contienne des fichiers texte\n",
    "!ls -lA \"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfait ! Nous avons des fichiers pr√™ts √† √™tre trait√©s ü¶æ !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Construire une liste de fichiers √† traiter\n",
    "\n",
    "Nous allons devoir charger chacun des fichiers du corpus et les passer √† notre mod√®le de langue `nlp`.\n",
    "\n",
    "Nous allons proc√©der de la fa√ßon suivante :\n",
    "\n",
    "1. nous allons construire la liste des chemins vers chacun de ces fichiers √† traiter\n",
    "2. nous allons d√©finir une fonction qui permet de charger le contenu de ces fichiers\n",
    "3. nous allons regarder les r√©sultats pour quelques fichiers\n",
    "4. finalement nous allons appeler notre mod√®le de langue avec le contenu de chacun de ces fichiers, pour stocker les entit√©s d√©tect√©es dans une grande liste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour lister les fichiers, nous allons utiliser le module Python [`glob`](https://docs.python.org/3/library/glob.html) qui permet d'obtenir une liste de fichier √† partir d'un motif.\n",
    "\n",
    "Nous allons utiliser un motif simple en indiquant un caract√®re joker `*` pour indiquer que n'importe quel caract√®re peut √™tre trouv√© √† cette position."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Corrigez l'extension des fichiers √† trouver dans la cellule suivante pour collecter la liste des fichiers texte √† traiter\n",
    "Nous allons afficher le contenu de cette liste pour v√©rifier que nous avons bien trouv√© les fichiers √† traiter.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "Remplacez le `*.json` par `*.txt`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "text_file_paths = glob(f\"{dataset_destination_dir}/French_ELTEC_NER_Open_Dataset/texts/*.json\")\n",
    "text_file_paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©tez la cellule suivante pour v√©rifier que nous avons bien trouv√© 100 fichiers\n",
    "<details>\n",
    "<summary>Indice</summary>\n",
    "V√©rifiez que la liste des noms de fichiers contient bien 100 √©l√©ments.\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "len(text_file_paths)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___(text_file_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Observation des r√©sultats pour quelques textes\n",
    "Avant de traiter les donn√©es, nous allons v√©rifier que le mod√®le de langue produit des r√©sultats raisonnables sur quelques exemples.\n",
    "\n",
    "Si ces r√©sultats sont satisfaisants, alors nous pourrons lancer un traitement plus large, et, plus tard, mesurer la performance de fa√ßon objective sur un √©chantillon repr√©sentatif, de taille suffisante, annot√© de fa√ßon fiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vous aider, voici une fonction `load_text(filename)` qui prend en param√®tre un chemin vers un fichier texte et renvoie la (longue) cha√Æne de caract√®res de son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text(filename: str) -> str:\n",
    "    \"\"\"Loads and returns the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the text file\n",
    "\n",
    "    Returns:\n",
    "        str: String representation of the content of the file. Newlines are preserved.\n",
    "    \"\"\"\n",
    "    with open(filename, encoding=\"utf8\") as in_file:\n",
    "        return \"\".join(in_file.readlines())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©ter la cellule suivante pour traiter et visualiser les entit√©s extraites d'un texte de votre choix\n",
    "Si n√©cessaire, consultez les √©tapes pr√©c√©dentes pour retrouver les op√©rations r√©alis√©es.\n",
    "\n",
    "Rappel : la variable qui pointe vers notre mod√®le de langue s'appelle `nlp`.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "some_filename = text_file_paths[10]\n",
    "some_text = load_text(some_filename)\n",
    "some_doc = nlp(some_text)\n",
    "displacy.render(some_doc, style=\"ent\", jupyter=True)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On choisit un fichier parmi la liste des fichiers disponibles\n",
    "some_filename = text_file_paths[10]\n",
    "# On charge son contenu\n",
    "some_text = load_text(____)\n",
    "# On applique notre mod√®le de langue pour extraire des entit√©s nomm√©es (entre autres)\n",
    "some_doc = ___(____)\n",
    "# On utilise displaCy pour visualiser les entit√©s nomm√©es d√©tect√©es dans ce texte\n",
    "____.render(____, style=____, jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'en pensez-vous ?**  \n",
    "‚Äî Pas si mal, √† premi√®re vue, pour un mod√®le de langue minimaliste !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Traiter les donn√©es de fa√ßon massive\n",
    "\n",
    "Nous allons traiter chacun des textes et r√©cup√©rer le texte des entit√©s nomm√©es de type \"`LOC`\" pour les ajouter √† une liste.\n",
    "\n",
    "Cette liste contiendra des √©l√©ments qui nous int√©ressent (comment \"Paris\", \"Bretagne\"), ne contiendra pas quelques √©l√©ments manqu√©s, et contiendra en plus quelques √©l√©ments de bruit faussement d√©tect√©s comme des entit√©s de type `LOC`.\n",
    "\n",
    "Afin de diminuer le plus possible le temps de calcul, nous allons r√©aliser un certain nombre d'optimisations :\n",
    "\n",
    "- nous allons charger les fichiers texte √† la demande pour limiter l'utilisation de la m√©moire de la machine et commencer √† les analyser d√®s qu'ils sont charg√©s (au lieu d'attendre de tous les charger) ‚Üí utilisation d'un g√©n√©rateur Python\n",
    "- nous allons temporairement [limiter les composants actifs de notre mod√®le de langue](https://spacy.io/usage/processing-pipelines#disabling) afin de ne calculer que les √©l√©ments n√©cessaires √† la reconnaissance d'entit√©s nomm√©es ‚Üí utilisation du *context manager* [`Language.select_pipes()`](https://spacy.io/api/language#select_pipes),\n",
    "- nous allons utiliser la fonctionnalit√© de traitement √† la vol√©e de spaCy pour acc√©l√©rer les calculs et limiter l'utilisation de la m√©moire ‚Üí m√©thode [`Language.pipe()`](https://spacy.io/api/language#pipe),\n",
    "- nous allons analyser les documents au fur et √† mesure de leur analyse pour en extraire les entit√©s qui nous int√©ressent ‚Üí parcours des √©l√©ments [`Doc.ents`](https://spacy.io/api/doc#ents) et s√©lection des √©l√©ments dont l'attribut [`Span.label_`](https://spacy.io/api/span#attributes) nous convient,\n",
    "- et finalement nous ne stockerons que le texte des entit√©s nomm√©es, et non l'objet [`Span`](https://spacy.io/api/span) complet qui contient une r√©f√©rence vers tout le texte du document, afin de limiter l'utilisation m√©moire.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üõ†Ô∏è Compl√©ter la cellule suivante pour traiter tous les fichiers texte du corpus\n",
    "Rappel : la variable qui pointe vers notre mod√®le de langue s'appelle `nlp`.\n",
    "\n",
    "Convention : nous d√©finissons une variable `all_loc_entities: list[str]` qui contiendra le texte de toutes nos entit√©s.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "texts = (load_text(filename) for filename in text_file_paths)\n",
    "all_loc_entities: list[str] = []\n",
    "with nlp.select_pipes(enable=\"ner\"):\n",
    "    for doc in nlp.pipe(texts):\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"LOC\":\n",
    "                all_loc_entities.append(ent.text)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ‚Üë l'instruction ci-dessus sert √† mesurer le temps d'ex√©cution de la cellule courante\n",
    "texts = (load_text(filename) for filename in text_file_paths)  # on charge les fichiers √† la demande avec un g√©n√©rateur\n",
    "all_loc_entities: list[str] = []  # la liste qui va stocker nos r√©sultats : une simple liste d'entit√©s nomm√©es\n",
    "with nlp.____(enable=____):  # on restreint les calculs au composant \"ner\" exclusivement pour aller plus vite\n",
    "    for doc in nlp.____(texts):  # on utilise le traitement √† la vol√©e\n",
    "        for ent in doc.____:  # on parcourt les entit√©s du document\n",
    "            if ent.label_ == ____:  # on ne conserve que les entit√©s du type qui nous int√©resse\n",
    "                all_loc_entities.append(ent.____)  # on ne conserve que le texte et pas toute l'entit√© pour √©viter de garder le document en m√©moire\n",
    "# On affiche le nombre d'entit√©s nomm√©es trouv√©es\n",
    "len(all_loc_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voici les premiers √©l√©ments de cette grande liste\n",
    "all_loc_entities[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∞ O√π en √™tes-vous ?\n",
    "\n",
    "**Si vous n'avez pas le temps d'aller plus loin, ce n'est pas grave** : vous pourrez finir cette activit√© chez vous.\n",
    "üéâ Vous avez d√©j√† r√©ussi √† produire des donn√©es dans un format qui peut √™tre utile pour une analyse ult√©rieure.\n",
    "**Vous pouvez passer directement √† l'√©tape 8 d'export des donn√©es** pour avoir une vision compl√®te de la phase d'extraction de donn√©es.\n",
    "\n",
    "ü§ì Dans ce qui suit, nous allons essayer d'aller plus loin pour :\n",
    "- mettre en place un protocole d'√©valuation rigoureux nous permettant de comparer la performance de diff√©rents mod√®les (et ne pas nous contenter du mod√®le le plus l√©ger de spaCy)\n",
    "- entra√Æner un mod√®le sp√©cialis√© pour l'analyse de nos donn√©es, en v√©rifiant bien qu'il nous apporte un gain par rapport aux mod√®les existants !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. √âvaluer objectivement la performance d'un mod√®le de langage ‚Äî *‚è±Ô∏è 5 mn*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Un probl√®me de d√©tection\n",
    "\n",
    "Dans le cas de la reconnaissance d'entit√©s nomm√©es, le probl√®me est g√©n√©ralement consid√©r√© comme un probl√®me de **d√©tection**, c'est-√†-dire qu'il s'agit de rep√©rer la position et le type de donn√©es d'int√©r√™t dans un ensemble de donn√©es : texte, image, son‚Ä¶\n",
    "\n",
    "D√©tecter un √©l√©ment dans du texte revient √† identifier :\n",
    "- sa position initiale,\n",
    "- sa position finale,\n",
    "- son type.\n",
    "\n",
    "C'est exactement pour d√©crire ce type d'objet que les [`Span`](https://spacy.io/api/span) existent : leurs attributs `start`, `end` et `label_` contiennent ces informations.\n",
    "\n",
    "L'exemple ci-dessous montre comment :\n",
    "1. cr√©er un document sans en extraire aucune autre information que les *tokens* gr√¢ce √† la m√©thode [`Language.make_doc(text)`](https://spacy.io/api/Language#attributes)\n",
    "2. cr√©er un objet [`Span`](https://spacy.io/api/Span#init) avec les param√®tres utiles :\n",
    "   - les positions correspondent au caract√®re (ou token) de d√©but, et au caract√®re (ou token) apr√®s la fin, index√©es √† partir de 0\n",
    "   - la valeur de son √©tiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 avec `Doc.char_span` \n",
    "# ‚Üí les positions sont correspondent √† des caract√®res !\n",
    "doc = nlp.make_doc(\"Il est parti de Paris t√¥t ce matin.\")\n",
    "span = doc.char_span(16, 21, label=\"LOC\")  \n",
    "span  # on affiche l'objet cr√©√© pour v√©rifier qu'on a saisi les bonnes valeurs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 avec la construction directe d'un `Span`\n",
    "# ‚Üí c'est pratique car les positions correspondent aux tokens : plus facile √† saisir\n",
    "# ‚Üí mais il faut indiquer le document auquel on fait r√©f√©rence\n",
    "from spacy.tokens import Span\n",
    "doc = nlp.make_doc(\"Il est parti de Paris t√¥t ce matin.\")\n",
    "span = Span(doc, 4, 5, label=\"LOC\")\n",
    "span  # on affiche l'objet cr√©√© pour v√©rifier qu'on a saisi les bonnes valeurs !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Bases th√©oriques\n",
    "\n",
    "Pour √©valuer objectivement la performance d'un syst√®me de traitement de donn√©es, il nous faut 3 choses :\n",
    "1. un **ensemble de couples (donn√©es d'entr√©e, donn√©e id√©ale de sortie)** ‚Äî exemple : un texte et la liste des positions et types des entit√©s nomm√©es √† d√©tecter\n",
    "2. les **donn√©es produites par le syst√®me** √† √©valuer pour chacune des donn√©es d'entr√©e de l'ensemble pr√©c√©dent\n",
    "3. une **mesure permettant de comparer** les donn√©es produites et les donn√©es attendues\n",
    "\n",
    "Nous venons de voir qu'il est possible de repr√©senter les donn√©es produites (on dit plus souvent *\"pr√©dites\"*) et les donn√©es attendues √† l'aide de d'objets [`Span`](https://spacy.io/api/Span#init).\n",
    "\n",
    "Mais **comment les comparer**, et surtout **calculer une valeur qui r√©sume la ressemblance entre deux ensembles** de positions et types pr√©dits ou attendus ?\n",
    "\n",
    "C'est tr√®s simple en r√©alit√©, car le probl√®me de d√©tection dispose de mesures standard et fiables :\n",
    "- la [**pr√©cision**](https://en.wikipedia.org/wiki/Precision_and_recall), not√©e $P$, qui mesure la quantit√© de bruit dans les r√©sultats.\n",
    "  Elle est d√©finie comme  \n",
    "  $$P = \\frac{\\text{nombre d'√©l√©ments corrects}}{\\text{nombre d'√©l√©ments d√©tect√©s}}$$\n",
    "- le [**rappel**](https://en.wikipedia.org/wiki/Precision_and_recall), not√© $R$, qui mesure la proportion d'√©l√©ments manqu√©s dans les r√©sultats.\n",
    "  Il est d√©fini comme  \n",
    "  $$R = \\frac{\\text{nombre d'√©l√©ments corrects}}{\\text{nombre d'√©l√©ments attendus}}$$\n",
    "- le [**F-score**](https://en.wikipedia.org/wiki/F-score), not√© $F$, qui synth√©tise ces deux indicateurs en calculant leur moyenne harmonique.\n",
    "  Il est d√©fini par \n",
    "  $$F = 2 \\times \\frac{P \\times R}{P + R}$$\n",
    "\n",
    "Pour chacune de ces mesures, la **valeur minimale (pire cas) est $0$**, et la **valeur maximale (d√©tection parfaite) est $1$**.\n",
    "Il est courant d'indiquer des pourcentages lorsqu'on parle de ces valeurs (il suffit de les multiplier par 100).\n",
    "\n",
    "#### üßê Bon, tout √ßa c'est bien joli, mais comment fait-on pour **savoir qu'un √©l√©ment pr√©dit correspond √† un √©l√©ment attendu** ?\n",
    "Dans notre cas, c'est tr√®s simple ! Il suffit de consid√©rer que les √©l√©ments doivent avoir **exactement la m√™me position et la m√™me √©tiquette.** Si un √©l√©ment attendu n'a aucune correspondance, alors on dit qu'il a √©t√© manqu√©, et au contraire si un √©l√©ment pr√©dit ne correspond √† aucun √©l√©ment attendu, alors on dit qu'il s'agit d'une fausse d√©tection (on dit aussi \"du bruit\").\n",
    "\n",
    "#### Mesures par classe\n",
    "En g√©n√©ral, on s'int√©resse √† un type de donn√©es particulier, aussi les outils de mesure rapportent g√©n√©ralement les mesures de pr√©cision, rappel et F-score pour chaque classe (par exemple \"LOC\"). Il s'agit du m√™me calcul que pr√©c√©demment, mais en restreignant les √©l√©ments consid√©r√©s √† un type d'√©tiquette pr√©cis.\n",
    "\n",
    "#### ü§ì Bon √† savoir : on donne de multiples noms aux donn√©es attendues :\n",
    "- donn√©es cibles (*targets*)\n",
    "- v√©rit√© terrain (*ground truth*)\n",
    "- valeurs de r√©f√©rence (*gold standard*)\n",
    "- ‚Ä¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Place √† la pratique !\n",
    "Nous allons g√©n√©rer des donn√©es pr√©dites et des donn√©es de r√©f√©rence factices pour quelques fragments de texte simplistes, et nous allons calculer les diff√©rents scores pour chacun d'entre eux, de mani√®re √† comprendre le comportement de la pr√©cision, du rappel et du F-score (celui qui nous int√©resse le plus).\n",
    "\n",
    "Avant de r√©aliser des mesures, nous avons besoin de comprendre le r√¥le de deux types d'objets spaCy suppl√©mentaires :\n",
    "- [`Scorer`](https://spacy.io/api/scorer) : il est responsable de la **comparaison entre les documents de r√©f√©rence et les documents pr√©dits**. Il renvoie les mesures pour toutes les donn√©es disponibles (donc pas seulement le NER si on ne pr√©cise rien). Dans notre cas, nous utiliserons la m√©thode [`Scorer.score_spans(examples, \"ents\")`](https://spacy.io/api/scorer#score_spans) qui nous permettra de restreindre l'√©valuation aux entit√©s nomm√©es. L'utilisation typique sera la suivante :  \n",
    "    ```python\n",
    "    scorer = Scorer()\n",
    "    scores = Scorer.score_spans(examples, \"ents\")\n",
    "    ```\n",
    "- [`Example`](https://spacy.io/api/example) : on l'a vu dans l'exemple pr√©c√©dent : il faut des exemples pour appeler le `Scorer`. Ces exemples correspondent √† des **paires de documents**, qui sont bas√©s sur le **m√™me texte** : un document contenant les **valeurs pr√©dites**, et un document contenant les **valeurs de r√©f√©rence**. Pour construire un exemple, on a donc besoin de cr√©er deux documents :\n",
    "    ```python\n",
    "    text = \"Bonjour de Lyon\"\n",
    "    doc_pred = nlp(text)\n",
    "    doc_ref = nlp.make_doc(text)\n",
    "    doc_ref.ents = [Span(doc_ref, 2, 3, \"LOC\")]\n",
    "    exemple = Example(doc_pred, doc_ref)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Compl√©tez les d√©finitions des Spans ci-dessous pour constituer une v√©rit√© terrain parfaite\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 4, 5, label=\"LOC\"),\n",
    "    ]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1 : La r√©f√©rence et la pr√©diction coincident\n",
    "text1 = \"Alice est all√©e √† Amsterdam l'an dernier et elle a trouv√© les canaux magnifiques.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(_____, __, __, label=____),\n",
    "    Span(_____, __, __, label=____),\n",
    "    ]\n",
    "doc1_ref.ents  # On verifie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Appelez √† pr√©sent notre mod√®le de langue sur le m√™me texte pour d√©finir la pr√©diction\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "doc1_pred = nlp(text1)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_pred = ___(_____)  # Par chance, le mod√®le de base indique les bons r√©sultats !\n",
    "doc1_pred.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Cr√©ez √† pr√©sent un `Example` qui contient les deux documents, et passez une __liste__ d'exemples au `Scorer`\n",
    "\n",
    "Faites attention √† l'ordre des param√®tres pour construire un [`Example`](https://spacy.io/api/example#init) : le premier est la pr√©diction, le second la r√©f√©rence.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "example = Example(doc1_pred, doc1_ref)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans([example], attr=\"ents\")\n",
    "score\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = Example(_____, _____)\n",
    "scorer = Scorer()\n",
    "score = scorer.score_spans(_____, attr=\"ents\")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit v√©rifier que tous les indicateurs sont √† 1 (la valeur maximale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ä pr√©sent, nous pouvons adapter l'exemple pr√©c√©dent pour tester les cas suivants et observer l'impact sur les diff√©rents scores :\n",
    "- une entit√© attendue est manqu√©e\n",
    "- une entit√© est pr√©dite par erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üë∑ Adaptez le code suivant pour tester les cas que nous venons de mentionner\n",
    "\n",
    "Nous allons simuler des d√©tections erron√©es plut√¥t que d'essayer de pi√©ger le mod√®le de langue.\n",
    "\n",
    "Observez l'impact des oublis et des fausses d√©tection sur la pr√©cision, le rappel et le F-score.\n",
    "\n",
    "<details>\n",
    "<summary>Solution cas 1</summary>\n",
    "\n",
    "```python\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc1_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    Span(doc1_ref, 0, 1, label=\"PER\"),  # Il manque Alex\n",
    "    Span(doc1_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary>Solution cas 2</summary>\n",
    "\n",
    "```python\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    Span(doc2_ref, 0, 1, label=\"PER\"),\n",
    "    Span(doc2_ref, 2, 3, label=\"PER\"),\n",
    "    Span(doc2_ref, 7, 8, label=\"LOC\"),\n",
    "    Span(doc2_ref, 10, 11, label=\"LOC\"),  # \"dernier\" d√©tect√© par erreur\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAS 1 : UNE ENTIT√â ATTENDUE EST MANQU√âE\n",
    "text1 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc1_ref = nlp.make_doc(text1)\n",
    "doc1_ref.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "# doc1_ref.ents  # On verifie\n",
    "doc1_pred = nlp.make_doc(text1)\n",
    "doc1_pred.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "example1 = Example(doc1_pred, doc1_ref)\n",
    "scorer.score_spans([example1], attr=\"ents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAS 2 : UNE ENTIT√â EST PR√âDITE PAR ERREUR\n",
    "text2 = \"Alice et Alex sont est all√©s √† Amsterdam l'an dernier.\"\n",
    "doc2_ref = nlp.make_doc(text2)\n",
    "doc2_ref.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "# doc2_ref.ents  # On verifie\n",
    "doc2_pred = nlp.make_doc(text2)\n",
    "doc2_pred.ents = [\n",
    "    ___, \n",
    "    ...\n",
    "    ]\n",
    "example2 = Example(doc2_pred, doc2_ref)\n",
    "scorer.score_spans([example2], attr=\"ents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Annoter un jeu de donn√©es complet : aper√ßu du probl√®me ‚Äî *‚è±Ô∏è 5 mn*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En g√©n√©ral, on a besoin de constituer et d'annoter un nouveau de donn√©es pour (au moins) une des deux raisons suivantes :\n",
    "1. Pour **√©valuer** rigoureusement la performance d'un ou plusieurs syst√®mes de traitement de donn√©es. Dans ce cas, on parle g√©n√©ralement de **jeu de test**, de **d√©veloppement** ou de **validation** (notions voisines sans √™tre exactement √©quivalentes). Il faut des donn√©es d'une quantit√© et d'une vari√©t√© suffisantes pour que les r√©sultats soient significatifs. Ce jeu de donn√©es ne peut pas contenir de donn√©es vues pendant l'entra√Ænement.\n",
    "2. Pour **entra√Æner** ou **sp√©cialiser** un mod√®le de langue bas√© sur une approche statistique. Dans ce cas, on parle de **jeu d'entra√Ænement** (*\"train set\"*). On a g√©n√©ralement besoin d'une quantit√© de donn√©es plus importante pour permettre la stabilisation des param√®tres statistiques du mod√®le. Ici aussi, ces donn√©es doivent √™tre suffisamment vari√©es pour permettre de capturer les subtilit√©s des donn√©es √† traiter, et assez repr√©sentatives pour capturer en priorit√© les g√©n√©ralit√©s.\n",
    "\n",
    "\n",
    "Dans les 2 cas, comme nous n'avons vu dans la section pr√©c√©dente, il faut pr√©parer :\n",
    "- des exemples de donn√©es d'entr√©e pour le syst√®me (√©chantillons de textes)\n",
    "- les sorties parfaites attendues pour ces donn√©es (dans le cas du NER, liste des entit√©s ‚Äî avec position et √©tiquette ‚Äî √† extraire).\n",
    "\n",
    "\n",
    "La fa√ßon la plus √©l√©mentaire de r√©aliser ce travail peut se d√©composer en :\n",
    "1. **identifier** un groupe de textes √† √©tiqueter,\n",
    "2. **importer** les textes dans un outil d'annotation et les **annoter**,\n",
    "3. **exporter** les donn√©es et les **convertir** dans un format adapt√©."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Quelques outils d'annotation\n",
    "- [ner-annotator](https://tecoholic.github.io/ner-annotator) : un petit outil libre et gratuit, tr√®s simple, qui a le m√©rite d'√™tre rapide √† utiliser pour illustrer la d√©marche.\n",
    "- [Brat](http://brat.nlplab.org/) : un outil libre et gratuit, plus complet, mais qui n√©cessite une installation.\n",
    "- [LabelStudio](https://labelstud.io/) : un outil autre libre et gratuit, assez complet, qui n√©cessite une installation mais peut aussi √™tre utilis√© en ligne.\n",
    "- [UniversalDataTool](https://universaldatatool.com) : un outil autre libre et gratuit, assez complet, qui n√©cessite une installation mais peut aussi √™tre utilis√© en ligne, et qui offre des fonctionnalit√©s de collaboration.\n",
    "- [TagTog](https://www.tagtog.com/) : un outil en ligne payant, offrant de nombreuses fonctionnalit√©s, mais qui ne semble plus trop maintenu.\n",
    "- [Prodigy](https://prodi.gy/) : un outil en ligne, payant, d√©velopp√© par les cr√©ateurs de spaCy, qui offre de nombreuses fonctionnalit√©s."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèóÔ∏è Place √† la pratique !\n",
    "\n",
    "Pour appr√©hender rapidement les joies et peines de l'annotation, nous vous proposons d'annoter (au moins partiellement) un texte choisi au hasard parmi ceux du corpus.\n",
    "\n",
    "Vous pouvez soit s√©lectionner un des textes du corpus sur votre ordinateur, soit en t√©l√©charger un au hasard depuis la machine virtuelle Colab en ex√©cutant la cellule ci-dessous.\n",
    "\n",
    "Ensuite, consultez la page <https://tecoholic.github.io/ner-annotator/> pour r√©aliser une annotation rapide :\n",
    "1. d√©posez votre fichier texte,\n",
    "2. configurer les tags √† utiliser,\n",
    "3. annotez le texte,\n",
    "4. t√©l√©chargez vos annotations au format JSON, qui pourront facilement √™tre [converties au format spaCy](https://spacy.io/api/data-formats#json-input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a file from the VM\n",
    "from google.colab import files\n",
    "files.download(text_file_paths[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon √† savoir : il existe plusieurs techniques pour pr√©m√¢cher le travail :\n",
    "- utiliser un premier mod√®le de langue qui donne des r√©sultats moyens, mais qui permet toutefois de gagner du temps (ce n'est pas toujours le cas)\n",
    "- chercher des motifs particuliers en utilisant un [`Matcher`](https://spacy.io/api/matcher) ; c'est rapide mais il faut avoir une bonne connaissance de notre corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ì Pour aller plus loin\n",
    "Voici quelques questions qu'on se pose g√©n√©ralement lorsqu'on d√©marre une campagne d'annotation.\n",
    "- Quelles √©tiquettes/labels utiliser ?\n",
    "- Quelles r√®gles suivre, comment g√©rer les ambigu√Øt√©s ?\n",
    "- Comment distribuer le travail entre plusieurs annotateurs ? Comment assurer la coh√©rence entre le travail des diff√©rents annotateurs ?\n",
    "- Comment diffuser notre travail, le partager, quelle licence utiliser ?\n",
    "\n",
    "Toutes ces questions m√©riteraient un atelier d√©di√©‚Ä¶\n",
    "\n",
    "*Sachez juste qu'il faut essayer de d√©marrer peu de donn√©es et valider l'int√©gralit√© du processus avant d'investir massivement dans un effort d'annotation.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entra√Æner un mod√®le sp√©cialis√© et comparer sa performance ‚Äî *‚è±Ô∏è 10 mn*\n",
    "\n",
    "Enfin, nous allons nous int√©resser √† l'entra√Ænement d'un mod√®le sp√©cialis√© pour nos donn√©es.\n",
    "En effet, il est parfois possible de d√©passer la performance des mod√®les \"sur √©tag√®re\" sur des cas particuliers mal g√©r√©s par des mod√®les g√©n√©ralistes.\n",
    "\n",
    "Nous allons utiliser des donn√©es d'entra√Ænement et de test que nous avons pr√©par√©es pour vous √† partir du jeu de donn√©es ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù.\n",
    "Si vous le souhaitez, vous pourrez regarder plus tard comment nous avons proc√©d√© dans les [notebooks](https://github.com/jchazalon/hn-ariane-ner-tuto-2023/blob/main/preparation/2-preparation-nettoyage-donnees-export-json.ipynb) [d√©di√©s](https://github.com/jchazalon/hn-ariane-ner-tuto-2023/blob/main/preparation/4-bench-mdls-convert-data-train-model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous utilisez Google Colab, vous devrez t√©l√©charger ces fichiers en ex√©cutant la cellule suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez la cellule suivante pour t√©l√©charger les jeux d'entra√Ænement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du r√©pertoire si n√©cessaire\n",
    "!mkdir -p ./dataset\n",
    "# T√©l√©chargement du dataset\n",
    "!wget -O ./dataset/train.spacy https://github.com/jchazalon/hn-ariane-ner-tuto-2023/raw/main/dataset/train.spacy\n",
    "!wget -O ./dataset/test.spacy https://github.com/jchazalon/hn-ariane-ner-tuto-2023/raw/main/dataset/test.spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 √âvaluation des mod√®les disponibles\n",
    "\n",
    "Nous allons commencer par mesurer la performance des mod√®les d√©j√† disponibles avant d'en entra√Æner un nouveau.\n",
    "\n",
    "Nous allons vous fournir deux √©l√©ments utiles :\n",
    "- un **jeu de test** `test_set` que nous utiliserons pour comparer les mod√®les (et qui ne sera pas utilis√© pour entra√Æner notre mod√®le par la suite),\n",
    "- une **fonction d'√©valuation** `evaluate(model, dataset)` qui permet d'√©valuer un mod√®le sur un jeu de test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß √Ä vous de jouer\n",
    "Comme indiqu√© dans [la documentation](https://spacy.io/models/fr), trois mod√®les en fran√ßais sont disponibles pour reconna√Ætre des entit√©s nomm√©es :\n",
    "- `fr_core_news_sm` : version *small*\n",
    "- `fr_core_news_md` : version *medium*\n",
    "- `fr_core_news_lg` : version *large*\n",
    "\n",
    "Utilisez la fonction `evaluate(model, dataset)` et le jeu de teste `train_set` fournis ci-apr√®s pour √©valuer la performance de ces trois mod√®les.\n",
    "\n",
    "N'oubliez pas de :\n",
    "- t√©l√©charger ces mod√®les si c'est n√©cessaire avec la commande `!python -m spacy download NOM_DU_MODELE`\n",
    "- de charger ces mod√®les avec l'instruction `model = spacy.load(NUM_DU_MODELE)`\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```python\n",
    "models_to_test = (\"fr_core_news_sm\", \"fr_core_news_md\", \"fr_core_news_lg\")\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Installing model '{model_name}'‚Ä¶\")\n",
    "    !python -m spacy download {model_name}\n",
    "for model_name in models_to_test:\n",
    "    print(f\"Try to load the model '{model_name}'‚Ä¶\")\n",
    "    model = spacy.load(model_name)\n",
    "    print(f\"Benchmarking the model '{model_name}' on our dataset‚Ä¶\")\n",
    "    scores = evaluate(model, test_set)\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"-\"*20)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "test_set = DocBin().from_disk(\"./dataset/test.spacy\")\n",
    "print(f\"Loaded a dataset with {len(test_set)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from spacy import Language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "def evaluate(ner_model: Language, dataset: Iterable[Doc], debug: bool=False) -> dict:\n",
    "    examples = []\n",
    "    for doc_ref in dataset.get_docs(ner_model.vocab):\n",
    "        text = doc_ref.text\n",
    "        # doc_pred = None\n",
    "        # with ner_model.select_pipes(enable=\"ner\"):  # does not work with trained model\n",
    "        #     doc_pred = ner_model(text)\n",
    "        doc_pred = ner_model(text)\n",
    "        if debug:\n",
    "            print(\"Pred.:\", [(ent.text, ent.label_) for ent in doc_pred.ents], \" ‚Üî Targ.:\", [(ent.text, ent.label_) for ent in doc_ref.ents])\n",
    "        example = Example(doc_pred, doc_ref)\n",
    "        examples.append(example)\n",
    "    \n",
    "    scorer = Scorer()\n",
    "    scores = scorer.score_spans(examples, \"ents\")\n",
    "    # print(scores[\"ents_f\"])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajoutez votre code ici pour √©valuer les diff√©rents mod√®les\n",
    "# N'h√©sitez pas √† utiliser plusieurs cellules"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans nos tests, nous avons obtenus les F-scores suivants pour les entit√©s de types `LOC`, pouvez-vous retrouver des valeurs similaires dans vos r√©sultats ?\n",
    "\n",
    "| Mod√®le | F-Score pour entit√©s `LOC` |\n",
    "|--------|---------------------------:|\n",
    "| `fr_core_news_sm` | 58% |\n",
    "| `fr_core_news_md` | 65% |\n",
    "| `fr_core_news_lg` | 68% |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Entra√Ænement d'un mod√®le l√©ger *from scratch*\n",
    "\n",
    "Un entra√Ænement *from scratch*, ou *√† partir de rien*, consiste √† apprendre un nouveau mod√®le depuis le d√©but, sans aucune connaissance autre que le jeu d'entra√Ænement.\n",
    "\n",
    "Par facilit√©, nous allons illustrer la capacit√© √† entra√Æner ou am√©liorer des mod√®les existants de spaCy avec un entra√Ænement de ce type, qui n√©cessite une dizaine de minutes de calcul sur un ordinateur portable.\n",
    "Bien entendu, d'autres techniques plus avanc√©es sont possibles, et nous les pr√©senterons rapidement √† la fin de cette section.\n",
    "Notre motivation ici est de vous permettre de prendre en main ce processus, et de l'am√©liorer par vous-m√™mes ensuite.\n",
    "\n",
    "Pour vous permettre d'entra√Æner votre mod√®le, nous vous fournissons un jeu d'entra√Ænement qui contient 70% du jeu de donn√©es ‚Äú[French ELTEC NER Open Dataset](http://hdl.handle.net/20.500.11752/OPEN-986)‚Äù, 30% ayant √©t√© r√©serv√©s pour le jeu de test.\n",
    "\n",
    "Les fichiers correspondant aux *train* et *test* *sets* sont disponibles dans le r√©pertoire `dataset/` :\n",
    "- `./dataset/train.spacy` : jeu d'entra√Ænement (*train set*)\n",
    "- `./dataset/test.spacy` : jeu de test (*test set*, aussi appel√© *dev set* ici)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entra√Æner votre mod√®le avec spaCy, vous allez devoir r√©aliser les actions suivantes :\n",
    "1. Cr√©er un fichier de configuration de base `base_config.cfg` √† l'aide de l'assistant en ligne <https://spacy.io/usage/training#quickstart>,\n",
    "2. Compl√©ter le fichier de configuration avec la commande [`!python -m spacy init fill-config ...`](https://spacy.io/api/cli#init-fill-config),\n",
    "3. Lancer l'entra√Ænement avec la commande [`!python -m spacy train ...`](https://spacy.io/api/cli#train),\n",
    "4. Charger le mod√®le appris avec la fonction [`spacy.load()`](https://spacy.io/api/top-level#spacy.load), l'√©valuer manuellement et l'utiliser sur un fichier jamais vu pendant l'entra√Ænement.\n",
    "\n",
    "Nous stockerons tous les fichiers de configuration et les mod√®les g√©n√©r√©s dans le r√©pertoire `training-scratch/` afin de centraliser l'information √† propos de l'entra√Ænement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Cr√©ez un fichier de configuration √† l'aide de l'assistant\n",
    "\n",
    "Visitez la page <https://spacy.io/usage/training#quickstart> et s√©lectionner les param√®tres suivants :\n",
    "- Language: fran√ßais\n",
    "- Composants: NER seul\n",
    "- Hardware: CPU dans le doute, GPU si vous disposez d'une machine avec un acc√©l√©rateur GPU\n",
    "- Optimize for: efficiency (vous pourrez s√©lectionner \"accuracy\" si vous lancez un entra√Ænement plus long)\n",
    "\n",
    "Ensuite, copiez-collez le contenu du fichier g√©n√©r√© dans la cellule ci-dessous pour cr√©er notre fichier de configuration.  \n",
    "Attention √† ne remplacer que le texte entre les d√©limiteurs `-------8<---------8<----------`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p training-scratch\n",
    "echo '\n",
    "# -------8<---------8<----------\n",
    "# This is an auto-generated partial config. To use it with 'spacy train'\n",
    "# you can run spacy init fill-config to auto-fill all default settings:\n",
    "# python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
    "[paths]\n",
    "train = null\n",
    "dev = null\n",
    "vectors = null\n",
    "[system]\n",
    "gpu_allocator = null\n",
    "\n",
    "[nlp]\n",
    "lang = \"fr\"\n",
    "pipeline = [\"tok2vec\",\"ner\"]\n",
    "batch_size = 1000\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.tok2vec]\n",
    "factory = \"tok2vec\"\n",
    "\n",
    "[components.tok2vec.model]\n",
    "@architectures = \"spacy.Tok2Vec.v2\"\n",
    "\n",
    "[components.tok2vec.model.embed]\n",
    "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
    "width = ${components.tok2vec.model.encode.width}\n",
    "attrs = [\"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"]\n",
    "rows = [5000, 1000, 2500, 2500]\n",
    "include_static_vectors = false\n",
    "\n",
    "[components.tok2vec.model.encode]\n",
    "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
    "width = 96\n",
    "depth = 4\n",
    "window_size = 1\n",
    "maxout_pieces = 3\n",
    "\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "\n",
    "[components.ner.model]\n",
    "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "state_type = \"ner\"\n",
    "extra_state_tokens = false\n",
    "hidden_width = 64\n",
    "maxout_pieces = 2\n",
    "use_upper = true\n",
    "nO = null\n",
    "\n",
    "[components.ner.model.tok2vec]\n",
    "@architectures = \"spacy.Tok2VecListener.v1\"\n",
    "width = ${components.tok2vec.model.encode.width}\n",
    "\n",
    "[corpora]\n",
    "\n",
    "[corpora.train]\n",
    "@readers = \"spacy.Corpus.v1\"\n",
    "path = ${paths.train}\n",
    "max_length = 0\n",
    "\n",
    "[corpora.dev]\n",
    "@readers = \"spacy.Corpus.v1\"\n",
    "path = ${paths.dev}\n",
    "max_length = 0\n",
    "\n",
    "[training]\n",
    "dev_corpus = \"corpora.dev\"\n",
    "train_corpus = \"corpora.train\"\n",
    "\n",
    "[training.optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "\n",
    "[training.batcher]\n",
    "@batchers = \"spacy.batch_by_words.v1\"\n",
    "discard_oversize = false\n",
    "tolerance = 0.2\n",
    "\n",
    "[training.batcher.size]\n",
    "@schedules = \"compounding.v1\"\n",
    "start = 100\n",
    "stop = 1000\n",
    "compound = 1.001\n",
    "\n",
    "[initialize]\n",
    "vectors = ${paths.vectors}\n",
    "# -------8<---------8<----------\n",
    "' > ./training-scratch/base_config.cfg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Compl√©ter le fichier de configuration\n",
    "Compl√©tez la commande [`!python -m spacy init fill-config ...`](https://spacy.io/api/cli#init-fill-config) suivante pour indiquer :\n",
    "- le fichier de configuration de base `./training-scratch/base_config.cfg`,\n",
    "- un fichier de configuration cible : nommez-le `config.cfg` et stockez-le dans le m√™me r√©pertoire.\n",
    "\n",
    "N'h√©sitez pas √† consulter la documentation.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy init fill-config ./training-scratch/base_config.cfg ./training-scratch/config.cfg\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "!python -m spacy init fill-config ___________   ___________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Lancer l'entra√Ænement\n",
    "Compl√©tez la commande [`!python -m spacy train ...`](https://spacy.io/api/cli#train) suivante pour indiquer :\n",
    "- le chemin vers le fichier de configuration\n",
    "- le chemin vers le r√©pertoire de sortie `./training-scratch/output`\n",
    "- le chemin vers le jeu d'entra√Ænement\n",
    "- le chemin vers le jeu de test\n",
    "\n",
    "N'h√©sitez pas √† consulter la documentation.\n",
    "\n",
    "<details>\n",
    "<summary>Solution</summary>\n",
    "\n",
    "```\n",
    "!python -m spacy train ./training-scratch/config.cfg --output ./training-scratch/output --paths.train ./dataset/train.spacy --paths.dev ./dataset/test.spacy\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train ________ --output ________ --paths.train ________ --paths.dev ________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ Bravo, vous avez r√©ussi √† entra√Æner un mod√®le ! üéä\n",
    "\n",
    "Deux variantes du mod√®le sont conserv√©es :\n",
    "- la derni√®re version, celle qui est optimis√©e √† chaque √©tape de l'apprentissage\n",
    "- la meilleure version, celle qui a donn√© les meilleurs r√©sultats sur le jeu de test/dev.\n",
    "\n",
    "ü§ì Il est m√™me possible de cr√©er un package Python facile √† partager, sauvegarder et r√©utiliser avec la commande [`spacy package`](https://spacy.io/api/cli#package)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Chargement du mod√®le entra√Æn√©, √©valuation et utilisation\n",
    "\n",
    "Nous allons √† pr√©sent charger et √©valuer le mod√®le qui vient d'√™tre entra√Æn√©.\n",
    "\n",
    "On s√©lectionne le meilleur mod√®le, qui n'est pas forc√©ment le dernier, afin d'esp√©rer les meilleurs r√©sultats possibles.\n",
    "\n",
    "Cette **√©valuation quantitative** sur **le jeu de test** nous permet d'avoir une estimation non biais√©e de la performance de ce mod√®le sur d'autres textes similaires qui n'ont pas √©t√© vus pendant l'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = spacy.load(\"./training-scratch/output/model-best\")\n",
    "evaluate(my_model, test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le F-score de ce mod√®le est plus faible, pour les entit√©s de type `LOC`, que les mod√®les d√©j√† disponibles.\n",
    "\n",
    "Il y a plusieurs raisons √† cela :\n",
    "- nous avons entra√Æn√© avec tr√®s peu de donn√©es\n",
    "- nous avons optimis√© l'apprentissage en int√©grant les entit√©s `PER` et `LOC`, et ce mod√®le s'av√®re meilleur sur les entit√©s `PER` que le mod√®le *small* de base ; le choix du crit√®re est important !\n",
    "\n",
    "Toutefois, ce petit mod√®le donne d√©j√† une meilleure pr√©cision (c'est-√†-dire qu'il produit moins de fausses d√©tections) que le petit mod√®le de base. Pour de l'extraction de donn√©es, cela peut d√©j√† √™tre un gain !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut √©galement appeler le mod√®les sur un texte du jeu de test afin d'avoir un **aper√ßu qualitatif** de ses r√©sultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_text = next(test_set.get_docs(my_model.vocab))\n",
    "doc_test = my_model(unseen_text)\n",
    "doc_test.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc_test, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 7.4 En r√©sum√© √† propos de l'entra√Ænement\n",
    "\n",
    "Nous avons vu qu'il √©tait simple d'entra√Æner un petit mod√®le *from scratch*, et vous devriez √† pr√©sent √™tre en mesure d'aller plus loin (hors du cadre de cette activit√©) en :\n",
    "- partant non plus de z√©ro, mais √† partir d'un mod√®le d√©j√† entra√Æn√© pour r√©utiliser les connaissances d√©j√† apprises (*transfer learning*)\n",
    "- utiliser un mod√®le plus puissant (mais aussi plus gourmand en ressources de calcul pour l'apprentissage)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export des donn√©es pour une utilisation ult√©rieure ‚Äî *‚è±Ô∏è 2 mn*\n",
    "\n",
    "Nous allons stocker les donn√©es produites dans un fichier JSON facile √† r√©utiliser et convertir.\n",
    "\n",
    "Nous allons sauvegarder ce fichier dans votre Drive ou √† l'emplacement que vous indiquerez ci-apr√®s.\n",
    "\n",
    "Nous allons √©galement vous montrer comment t√©l√©charger directement le fichier vers votre machine locale si vous utilisez Google Colab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß Ex√©cutez les cellules suivantes, en modifiant le chemin vers l'emplacement de sauvegarde du fichier si n√©cessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEMIN VERS LE FICHIER DE SAUVEGARDE\n",
    "PATH_TO_SAVE_FILE = f\"/gdrive/My Drive/{FOLDER_NAME}/en_french_eltec_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition d'une fonction de sauvegarde\n",
    "import json\n",
    "def save_my_entities(data: list[str], filename: str):\n",
    "    with open(filename, mode='w', encoding=\"utf8\") as out_file:\n",
    "        json.dump(data, out_file, indent=0)\n",
    "    print(f\"Your data was successfully save to '{filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du fichier\n",
    "save_my_entities(all_loc_entities, PATH_TO_SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√©l√©chargement direct du fichier depuis la VM Colab\n",
    "files.download(PATH_TO_SAVE_FILE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ C'est tout pour cette fois !\n",
    "\n",
    "Nous esp√©rons que cette activit√© a √©t√© enrichissante.\n",
    "\n",
    "N'h√©sitez pas √† **donner rapidement votre avis anonyme üì¢** via [ce **formulaire** üìù](https://docs.google.com/forms/d/e/1FAIpQLSfS46qZC5Bz7ultNm2tLLYl6b72HonbERt1srpaoLUes-tNJA/viewform?usp=sf_link) pour nous aider √† l'am√©liorer.\n",
    "\n",
    "Finalement, notez que plusieurs points n'ont pas pu √™tre abord√©s ici pour des raisons de temps :\n",
    "- la s√©lection des donn√©es du corpus,\n",
    "- la conversion des donn√©es vers et depuis la plateforme d'annotation,\n",
    "- la pr√©paration des donn√©es d'entra√Ænement et d'√©valuation,\n",
    "- les [matchers](https://spacy.io/api/matcher),\n",
    "- utiliser d'autres outils, comme la biblioth√®que [Transformers d'HuggingFace](https://huggingface.co/transformers/).\n",
    "\n",
    "Nous avons r√©alis√© toutes ces op√©rations pour la pr√©paration de cette activit√©, et vous pourrez regarder nos [notebooks de brouillon](https://github.com/jchazalon/hn-ariane-ner-tuto-2023/tree/main/preparation) si vous le souhaitez, afin de disposer d'exemples de code √† r√©utiliser.\n",
    "\n",
    "üëç Bonne analyse de donn√©es !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hn-ariane-ner-tuto-2023-PwR_0BG5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
